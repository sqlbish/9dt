{"dbEnvironment":"snowflake","version":"1.38.11","jobsTree":{"id":66048,"name":"ROOT","children":[{"id":77057,"name":"Jobs","children":[{"id":161018,"name":"DropTokenGame","children":[],"jobs":[{"id":160959,"name":"Import 9DT","description":"","type":"ORCHESTRATION"}]}],"jobs":[]}],"jobs":[]},"orchestrationJobs":[{"id":160959,"revision":262,"created":1564724400067,"timestamp":1564724400067,"components":{"160960":{"id":160960,"inputCardinality":"ZERO","outputCardinality":"MANY","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":444132438,"x":-1760,"y":-32,"width":32,"height":32,"inputConnectorIDs":[],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[162703],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Start 0"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"160964":{"id":160964,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-1184,"y":112,"width":32,"height":32,"inputConnectorIDs":[161008],"outputSuccessConnectorIDs":[162249],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Upload the Player JSON data into AWS S3 Bucket"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"#Python script to upload the JSON data into AWS S3 bucket\n#It will then be imported into a staging table from the S3 bucket\n\nimport boto3\n\ns3 = boto3.client(\n    's3',\n    region_name='us-west-2',\n    aws_access_key_id='AKIAI63D7ZTJCJC2XKRA',\n    aws_secret_access_key='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'\n)\n\ns3.upload_file('/var/cache/tomcat8/temp/player_profile.json','98point6','player_profile.json')\n"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Jython"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":false}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"160986":{"id":160986,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-1184,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162213],"outputSuccessConnectorIDs":[161008],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Get Requests to the API to retrieve  Player Data in JSON"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"# importing the requests library\nimport requests\nimport json\n\n# api-endpoint\n# loop iterator to infinite number until an empty array is resulted from the get http request\nn = [1]\nfor pageNum in n:\n    n.append(pageNum + 1)\n    URL = \"https://x37sv76kth.execute-api.us-west-1.amazonaws.com/prod/users?page=\" + str(pageNum)\n    print(URL)\n\n\n# sending get request and saving the response as response object\n    r = requests.get(url = URL)\n\n# extracting data in json format\n    data = r.json()\n    print(data)\n    if not data:\n        print('a is an empty list')\n        break\n\n# writing the output to a local file on the server\n    with open('/var/cache/tomcat8/temp/player_profile.json', 'a') as outfile:\n        json.dump(data, outfile)\n\n\n\n\n\n\n"}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Jython"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":false}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162163":{"id":162163,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-1504,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162706],"outputSuccessConnectorIDs":[162213],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Load Game Data CSV file from AWS S3 Bucket into a Staging table"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_TEST; --Schema to hold staging tables\n--USE WAREHOUSE LARGE; --Computing warehouse in Snowflake to process queries\n\n\n--Create S3 stage poiting to the AWS S3 bucket location\n--This is where the game_data.csv file lives and is the starting point of this load\nCREATE OR REPLACE STAGE BISHAL_TEST.BISHAL_STAGE URL='s3://98point6' \nCREDENTIALS=(AWS_KEY_ID='AKIAI63D7ZTJCJC2XKRA' AWS_SECRET_KEY='0CTN3QeSfW5yXplKUV+8PiubVKfZjNi6EKHL6mq1'); \n\n\n--Create staging table in Snowflake Database to stage the game_data.csv data imported from the AWS s3 stage\nCREATE OR REPLACE TABLE BISHAL_TEST.DTG_STAGING (GAME_ID VARCHAR(500), PLAYER_ID VARCHAR(500), MOVE_NUMBER INT,COLUMN_NUMBER SMALLINT,RESULT VARCHAR(5));\n\n--Clean up the previous session data\nTRUNCATE TABLE BISHAL_TEST.DTG_STAGING\n\n--Now import the game_data.csv using the copy into/S3 Load snowflake sqnosql command to import the data into the staging table\nCOPY INTO BISHAL_TEST.DTG_STAGING \nFROM @BISHAL_TEST.BISHAL_STAGE\nPATTERN='(?i).*game_data.*.csv'\nFILE_FORMAT= (\n\tTYPE=CSV\n\tSKIP_HEADER = 1\n\tCOMPRESSION=AUTO,\n\tTRIM_SPACE=FALSE,\n\tERROR_ON_COLUMN_COUNT_MISMATCH=FALSE,\n\tEMPTY_FIELD_AS_NULL=TRUE\n)\nON_ERROR='skip_file'\nPURGE=FALSE\nTRUNCATECOLUMNS=FALSE\nFORCE=FALSE;\n\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162246":{"id":162246,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-832,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162249],"outputSuccessConnectorIDs":[162351],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Load the Player JSON data from AWS S3  Bucket into a temp sql variant table"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_TEST; --Schema to hold staging tables\n--USE WAREHOUSE LARGE; --Computing warehouse in Snowflake to process queries\n\n--Create S3 stage poiting to the AWS S3 bucket location\n--This is where the player data JSON will be staged after it is downloaded from the get api requests\nCREATE STAGE IF NOT EXISTS BISHAL_TEST.BISHAL_STAGE URL='s3://98point6' \nCREDENTIALS=(AWS_KEY_ID='AKIAI63D7ZTJCJC2XKRA' AWS_SECRET_KEY='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'); \n\n--Create JSON file format to be used to import the player json file into a sql variant staging table\nCREATE FILE FORMAT IF NOT EXISTS \"BISHAL_TEST\".FORMAT_NDJSON TYPE = 'JSON' COMPRESSION = 'AUTO' ENABLE_OCTAL = FALSE ALLOW_DUPLICATE = FALSE STRIP_OUTER_ARRAY = FALSE STRIP_NULL_VALUES = FALSE IGNORE_UTF8_ERRORS = FALSE COMMENT = 'File format for importing Semi-Structured data into Snowfake';\n\n--Create staging table in Snowflake Database to stage the player json data as variant type imporrted from the AWS s3 stage\nCREATE TABLE IF NOT EXISTS BISHAL_TEST.PLAYER_PROFILE_JSON (JSON VARIANT);\n\n--Clean up previous sessions data\nTRUNCATE TABLE BISHAL_TEST.PLAYER_PROFILE_JSON;\n\n--Now import the player JSON data using snowflake sqnosql parse json command to import the data into the staging table\nINSERT INTO BISHAL_TEST.PLAYER_PROFILE_JSON\nSELECT T.VALUE FROM @BISHAL_TEST.BISHAL_STAGE/player_profile.json (file_format => 'BISHAL_TEST.FORMAT_NDJSON') as S, table(flatten(S.$1,'')) T;\n\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162348":{"id":162348,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-832,"y":112,"width":32,"height":32,"inputConnectorIDs":[162351],"outputSuccessConnectorIDs":[162629],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Parse and Load flattened Player JSON data into a structured staging table"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_TEST; --Schema to hold staging tables\n--USE WAREHOUSE LARGE; --Computing warehouse in Snowflake to process queries\n\n--Create a staging table to stage the flattened JSON player data\nCREATE TABLE IF NOT EXISTS BISHAL_TEST.PLAYER_PROFILE_STAGING\n(\n  PLAYER_ID VARCHAR(500),\n  FIRST_NAME VARCHAR(100),\n  LAST_NAME VARCHAR(100),\n  GENDER VARCHAR(10),\n  DOB TIMESTAMP WITH TIME ZONE,\n  EMAIL VARCHAR(100),\n  PHONENUMBER VARCHAR(40),\n  CELLNUMBER VARCHAR(40),\n  NATIONALITY VARCHAR(5),\n  REGISTERED_DATE TIMESTAMP WITH TIME ZONE,\n  USERNAME VARCHAR(40)\n  \n);\n\n--Clean up previous session data\nTRUNCATE TABLE BISHAL_TEST.PLAYER_PROFILE_STAGING;\n\n--Flatten/Parse the JSON data into structured data and import into the staging table\nINSERT INTO BISHAL_TEST.PLAYER_PROFILE_STAGING\nSELECT \n  JSON:id::int as Player_Id,\n  JSON:data.name.first::varchar as First_Name,\n  JSON:data.name.last::varchar as Last_Name,\n  JSON:data.gender::varchar as Gender,\n  JSON:data.dob::varchar as Dob,\n  JSON:data.email::varchar as Email,\n  JSON:data.phone::varchar as PhoneNumber,\n  JSON:data.cell::varchar as CellNumber,\n  JSON:data.nat::varchar as Nationality,\n  JSON:data.registered::varchar as RegisteredDate,\n  JSON:data.login.username::varchar as UserName\nFROM BISHAL_TEST.PLAYER_PROFILE_JSON;"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162626":{"id":162626,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-496,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162629],"outputSuccessConnectorIDs":[162659],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Create Dim and Fact Tables"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_DM; --Schema to hold Dim and Fact tables\n--USE WAREHOUSE SMALL; --Computing warehouse in Snowflake to process queries\n\n/* ---------------------------------------------------------------------- */\n/* Script generated with: DeZign for Databases V10.0.2                    */\n/* Target DBMS:           PostgreSQL 9                                    */\n/* Project file:          9DT_DataModel.dez                               */\n/* Project name:          9DT Players and Games                                                */\n/* Author:                Bishal Gupta                                               */\n/* Script type:           Database creation script                        */\n/* Created on:            2019-07-31 19:41                                */\n/* ---------------------------------------------------------------------- */\n\n\n/* ---------------------------------------------------------------------- */\n/* Add tables                                                             */\n/* ---------------------------------------------------------------------- */\n\n/* ---------------------------------------------------------------------- */\n/* Add table \"DIM_PLAYER\"                                                 */\n/* ---------------------------------------------------------------------- */\n\n--New Schema to hold the data warehouse tables for 9dt\nCREATE SCHEMA IF NOT EXISTS BISHAL_DM;\n\nUSE SCHEMA BISHAL_DM;\n\nCREATE TABLE IF NOT EXISTS DIM_PLAYER (\n    DIMPLAYER_KEY INTEGER AUTOINCREMENT NOT NULL,\n    PLAYER_ID CHARACTER VARYING(500),\n    FIRST_NAME CHARACTER VARYING(40),\n    LAST_NAME CHARACTER VARYING(40),\n    EMAIL CHARACTER VARYING(40),\n    NATIONALITY CHARACTER VARYING(5),\n    CREATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    CREATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    UPDATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    UPDATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    CONSTRAINT PK_DIM_PLAYER PRIMARY KEY (DIMPLAYER_KEY)\n);\n\n/* ---------------------------------------------------------------------- */\n/* Add table \"DIM_GAME\"                                                   */\n/* ---------------------------------------------------------------------- */\n\nCREATE TABLE IF NOT EXISTS DIM_GAME (\n    DIMGAME_KEY INTEGER AUTOINCREMENT NOT NULL,\n    GAME_ID CHARACTER VARYING(500),\n    CREATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    CREATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    UPDATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    UPDATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    CONSTRAINT PK_DIM_GAME PRIMARY KEY (DIMGAME_KEY)\n);\n\n/* ---------------------------------------------------------------------- */\n/* Add table \"DIM_RESULT\"                                                 */\n/* ---------------------------------------------------------------------- */\n\nCREATE TABLE IF NOT EXISTS DIM_RESULT (\n    DIMRESULT_KEY INTEGER AUTOINCREMENT NOT NULL,\n    RESULT CHARACTER VARYING(5),\n    CREATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    CREATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    UPDATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    UPDATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    CONSTRAINT PK_DIM_RESULT PRIMARY KEY (DIMRESULT_KEY)\n);\n\nCOMMENT ON COLUMN DIM_RESULT.RESULT IS 'Game Results for Example Win and Draw';\n\n/* ---------------------------------------------------------------------- */\n/* Add table \"FACT_GAME\"                                                  */\n/* ---------------------------------------------------------------------- */\n\nCREATE TABLE IF NOT EXISTS FACT_GAME (\n    FACT_GAME_KEY INTEGER AUTOINCREMENT NOT NULL,\n    DIMGAME_KEY INTEGER,\n    DIMPLAYER_KEY INTEGER,\n    MOVE_NUMBER INTEGER,\n    COLUMN_NUMBER INTEGER,\n    CREATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    CREATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    UPDATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    UPDATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    CONSTRAINT PK_FACT_GAME PRIMARY KEY (FACT_GAME_KEY)\n);\n\n/* ---------------------------------------------------------------------- */\n/* Add table \"FACT_RESULT\"                                                */\n/* ---------------------------------------------------------------------- */\n\nCREATE TABLE IF NOT EXISTS FACT_RESULT (\n    FACT_RESULT_KEY INTEGER AUTOINCREMENT NOT NULL,\n    DIMGAME_KEY INTEGER,\n    DIMRESULT_KEY INTEGER,\n    CREATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    CREATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    UPDATE_DATE TIMESTAMP WITH TIME ZONE DEFAULT CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP())  NOT NULL,\n    UPDATE_BY CHARACTER VARYING(250) DEFAULT CURRENT_USER()  NOT NULL,\n    CONSTRAINT PK_FACT_RESULT PRIMARY KEY (FACT_RESULT_KEY)\n);\n\n/* ---------------------------------------------------------------------- */\n/* Add foreign key constraints                                            */\n/* ---------------------------------------------------------------------- */\n\nALTER TABLE FACT_GAME ADD CONSTRAINT DIM_GAME_FACT_GAME \n    FOREIGN KEY (DIMGAME_KEY) REFERENCES DIM_GAME (DIMGAME_KEY);\n\nALTER TABLE FACT_GAME ADD CONSTRAINT DIM_PLAYER_FACT_GAME \n    FOREIGN KEY (DIMPLAYER_KEY) REFERENCES DIM_PLAYER (DIMPLAYER_KEY);\n\nALTER TABLE FACT_RESULT ADD CONSTRAINT DIM_GAME_FACT_RESULT \n    FOREIGN KEY (DIMGAME_KEY) REFERENCES DIM_GAME (DIMGAME_KEY);\n\nALTER TABLE FACT_RESULT ADD CONSTRAINT DIM_RESULT_FACT_RESULT \n    FOREIGN KEY (DIMRESULT_KEY) REFERENCES DIM_RESULT (DIMRESULT_KEY);\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162656":{"id":162656,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-496,"y":112,"width":32,"height":32,"inputConnectorIDs":[162659],"outputSuccessConnectorIDs":[162820],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Populate Dim and Fact tables from the Staging data"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_DM; --Schema to hold Dim and Fact tables\n--USE WAREHOUSE LARGE; --Computing warehouse in Snowflake to process queries\n\n\n--Populate Dim Player table\nMERGE INTO BISHAL_DM.DIM_PLAYER AS T \nUSING BISHAL_TEST.PLAYER_PROFILE_STAGING AS S \n     ON T.PLAYER_ID = S.PLAYER_ID  \nWHEN MATCHED \n        AND\n        (T.FIRST_NAME <> S.FIRST_NAME OR\n        T.LAST_NAME <> S.FIRST_NAME OR\n        T.EMAIL <> S.EMAIL OR\n        T.NATIONALITY <> S.NATIONALITY)\nTHEN UPDATE SET \n        T.FIRST_NAME = S.FIRST_NAME,\n        T.LAST_NAME = S.FIRST_NAME,\n        T.EMAIL = S.EMAIL,\n        T.NATIONALITY = S.NATIONALITY,\n        T.UPDATE_DATE = CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        T.UPDATE_BY = CURRENT_USER()\nWHEN NOT MATCHED THEN INSERT \n     (\t\n        PLAYER_ID,\n        FIRST_NAME,\n        LAST_NAME,\n        EMAIL,\n        NATIONALITY,\n        CREATE_DATE,\n        CREATE_BY  \n     ) \n     VALUES\n     ( \n        S.PLAYER_ID,\n        S.FIRST_NAME,\n        S.LAST_NAME,\n        S.EMAIL,\n        S.NATIONALITY,\n        CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        CURRENT_USER()\n     );\n     \n--SELECT * FROM BISHAL_DM.DIM_PLAYER;     \n\n--Populate Dim Game table\nMERGE INTO BISHAL_DM.DIM_GAME AS T --Doing merge in case there are any game attributes to update in future\nUSING ( SELECT DISTINCT GAME_ID FROM BISHAL_TEST.DTG_STAGING) AS S \n     ON T.GAME_ID = S.GAME_ID  \nWHEN MATCHED THEN UPDATE SET \n        T.UPDATE_DATE = CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        T.UPDATE_BY = CURRENT_USER()\nWHEN NOT MATCHED THEN INSERT \n     (\t\n        GAME_ID,\n        CREATE_DATE,\n        CREATE_BY  \n     ) \n     VALUES\n     ( \n        S.GAME_ID,\n        CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        CURRENT_USER()\n     );\n     \n-- SELECT * FROM BISHAL_DM.DIM_GAME ORDER BY 1     \n\n--Populate Dim Result table\nMERGE INTO BISHAL_DM.DIM_RESULT AS T --Doing merge in case there are any additional result table attributes to update in future\nUSING (SELECT DISTINCT RESULT FROM BISHAL_TEST.DTG_STAGING WHERE RESULT IS NOT NULL) AS S \n     ON IFNULL(T.RESULT,'') = IFNULL(S.RESULT, '')\nWHEN MATCHED THEN UPDATE SET \n        T.UPDATE_DATE = CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        T.UPDATE_BY = CURRENT_USER()\nWHEN NOT MATCHED THEN INSERT \n     (\t\n        RESULT,\n        CREATE_DATE,\n        CREATE_BY  \n     ) \n     VALUES\n     ( \n        S.RESULT,\n        CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        CURRENT_USER()\n     );\n     \n-- SELECT * FROM BISHAL_DM.DIM_RESULT ORDER BY 1 \n\n--Populate Fact Game table\nINSERT INTO BISHAL_DM.FACT_GAME \n         ( DIMGAME_KEY,\n          DIMPLAYER_KEY,\n          MOVE_NUMBER,\n          COLUMN_NUMBER,\n          CREATE_DATE,\n          CREATE_BY\n          )\nSELECT \n        DG.DIMGAME_KEY,\n        --DTG.GAME_ID,\n        DP.DIMPLAYER_KEY,\n        --DTG.PLAYER_ID,\n        DTG.MOVE_NUMBER,\n        DTG.COLUMN_NUMBER,\n        CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        CURRENT_USER\nFROM BISHAL_TEST.DTG_STAGING DTG --Staged source data\nLEFT JOIN BISHAL_DM.DIM_GAME DG --Dim Game\n        ON DTG.GAME_ID = DG.GAME_ID \nLEFT JOIN BISHAL_DM.DIM_PLAYER DP --Dim Player\n        ON DTG.PLAYER_ID = DP.PLAYER_ID;              \n\n--select * from BISHAL_DM.FACT_GAME;\n\n--Update Fact Game table as needed ( May depend on business process/need for update in measure)\nUPDATE BISHAL_DM.FACT_GAME FG --Update syntax is Snowflake is different TSQL\nSET\n        FG.MOVE_NUMBER = FGU.MOVE_NUMBER,\n        FG.COLUMN_NUMBER = FGU.COLUMN_NUMBER,\n        FG.UPDATE_DATE = CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        FG.UPDATE_BY = CURRENT_USER\nFROM\n        (        \n        SELECT \n                DG.DIMGAME_KEY,\n                DP.DIMPLAYER_KEY,\n                DTG.MOVE_NUMBER,\n                DTG.COLUMN_NUMBER,\n                CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n                CURRENT_USER\n        FROM BISHAL_TEST.DTG_STAGING DTG --Staged source data\n        LEFT JOIN BISHAL_DM.DIM_GAME DG --Dim Game\n                ON DTG.GAME_ID = DG.GAME_ID \n        LEFT JOIN BISHAL_DM.DIM_PLAYER DP --Dim Player\n                ON DTG.PLAYER_ID = DP.PLAYER_ID\n                ) FGU\nWHERE\n        FG.DIMGAME_KEY = FGU.DIMGAME_KEY\n        AND FG.DIMPLAYER_KEY = FGU.DIMPLAYER_KEY\n        AND FG.MOVE_NUMBER <> FGU.MOVE_NUMBER\n        AND FG.COLUMN_NUMBER <> FG.COLUMN_NUMBER;              \n\n--Populate Fact Result table\nINSERT INTO BISHAL_DM.FACT_RESULT \n         (DIMGAME_KEY,\n          DIMRESULT_KEY,\n          CREATE_DATE,\n          CREATE_BY\n          )\nSELECT \n        DG.DIMGAME_KEY,\n        --DTG.GAME_ID,\n        DR.DIMRESULT_KEY,\n        --DTG.RESULT,\n        CONVERT_TIMEZONE('UTC', CURRENT_TIMESTAMP()),\n        CURRENT_USER\nFROM BISHAL_TEST.DTG_STAGING DTG --Staged source data\nLEFT JOIN BISHAL_DM.DIM_GAME DG --Dim Game\n        ON DTG.GAME_ID = DG.GAME_ID \nLEFT JOIN BISHAL_DM.DIM_RESULT DR --Dim Result\n        ON DTG.RESULT = DR.RESULT\nWHERE DTG.RESULT IS NOT NULL;\n\n--SELECT * FROM BISHAL_DM.FACT_RESULT"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162697":{"id":162697,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-1616,"y":-112,"width":32,"height":32,"inputConnectorIDs":[162703],"outputSuccessConnectorIDs":[162706],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Create Database and Schema to hold Staging and Target tables"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"USE ROLE BI_DBA;\nUSE WAREHOUSE SMALL; --Computing warehouse in Snowflake to process queries\n\nCREATE DATABASE ANALYTICS_GAME;\n\nCREATE SCHEMA IF NOT EXISTS BISHAL_TEST;\n\nCREATE SCHEMA IF NOT EXISTS BISHAL_DM;"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162815":{"id":162815,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-288,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162820],"outputSuccessConnectorIDs":[162930],"outputFailureConnectorIDs":[162935],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Create Views to provide Analysis on the data"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"--USE ANALYTICS_GAME; --Target Database in Snowflake \n--USE ROLE BI_DBA;\n--USE SCHEMA BISHAL_DM; --Schema to hold Dim and Fact tables\n--USE WAREHOUSE SMALL; --Computing warehouse in Snowflake to process queries\n\n\n--Query #1 Out of all the games, what is the percentile rank of each column used as the ﬁrst move in a game? \n--That is, when the ﬁrst player is choosing a column for their ﬁrst move, which column most frequently leads to that player winning the game? \nCREATE VIEW IF NOT EXISTS BISHAL_DM.VW_RankBy_WinningColumn_FirstMove\nAS\nSELECT  FG.COLUMN_NUMBER, \n        COUNT(*) as CntofFirstMove, \n        RANK() OVER (ORDER BY COUNT(*) DESC) AS Rank\n        FROM BISHAL_DM.FACT_GAME FG\nJOIN BISHAL_DM.FACT_RESULT FR\n        ON FG.DIMGAME_KEY = FR.DIMGAME_KEY\nJOIN BISHAL_DM.DIM_RESULT DR\n        ON FR.DIMRESULT_KEY = DR.DIMRESULT_KEY\nWHERE DR.RESULT = 'win'\n        AND FG.MOVE_NUMBER = 1\nGROUP BY FG.COLUMN_NUMBER\nORDER BY RANK;\n\n\n--Query #2, How many games has each nationality participated in? \\\nCREATE VIEW IF NOT EXISTS BISHAL_DM.VW_Count_of_GamesPlayed_ByNationality\nAS\nSELECT \n        DP.NATIONALITY,\n        COUNT(DISTINCT DG.GAME_ID) as CountofGamesParticipated\n FROM BISHAL_DM.FACT_GAME FG\n JOIN BISHAL_DM.DIM_GAME DG\n        ON FG.DIMGAME_KEY = DG.DIMGAME_KEY\n JOIN BISHAL_DM.DIM_PLAYER DP\n        ON FG.DIMPLAYER_KEY = DP.DIMPLAYER_KEY\n GROUP BY DP.NATIONALITY\n ORDER BY DP.NATIONALITY; \n \n \n \n --Query #3.Marketing wants to send emails to players that have only played a single game. \n --The email will be customized based on whether or not the player won, lost, or drew the game. Which players should receive an email, and with what customization? \nCREATE VIEW IF NOT EXISTS BISHAL_DM.VW_Players_Played_SingleGame\nSELECT \n        DISTINCT\n        PG.FIRST_NAME,\n        PG.LAST_NAME,\n        PG.EMAIL,\n        IFNULL(DR.RESULT,'lost') as Game_Result\n\nFROM \n        ( \n        SELECT  --Get the player info that have only played single game\n                DP.DIMPLAYER_KEY,\n                DP.PLAYER_ID, \n                DP.FIRST_NAME,\n                DP.LAST_NAME,\n                DP.EMAIL     \n               FROM BISHAL_DM.DIM_PLAYER DP\n        JOIN BISHAL_DM.FACT_GAME FG \n                ON DP.DIMPLAYER_KEY = FG.DIMPLAYER_KEY\n        JOIN BISHAL_DM.DIM_GAME DG\n                ON FG.DIMGAME_KEY = DG.DIMGAME_KEY   \n        GROUP BY  \n                DP.DIMPLAYER_KEY,\n                DP.PLAYER_ID, \n                DP.FIRST_NAME,\n                DP.LAST_NAME,\n                DP.EMAIL\n        HAVING COUNT(distinct DG.GAME_ID) = 1     \n        )PG   \nLEFT JOIN (SELECT * FROM BISHAL_DM.FACT_GAME FG1 --Get the GameKey/GameId row from the game fact table with max mover_number, this row tells the game result\n                    WHERE MOVE_NUMBER =\n                       ( SELECT MAX(MOVE_NUMBER) FROM  BISHAL_DM.FACT_GAME FG2\n                          WHERE FG1.DIMGAME_KEY = FG2.DIMGAME_KEY)\n                          AND FG1.DIMGAME_KEY) FG\nON PG.DIMPLAYER_KEY = FG.DIMPLAYER_KEY\nLEFT JOIN BISHAL_DM.FACT_RESULT FR\nON FG.DIMGAME_KEY = FR.DIMGAME_KEY\nLEFT JOIN BISHAL_DM.DIM_RESULT DR\nON FR.DIMRESULT_KEY = DR.DIMRESULT_KEY\nORDER BY PG.FIRST_NAME, PG.LAST_NAME;\n\n "}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162927":{"id":162927,"inputCardinality":"ONE","outputCardinality":"ZERO","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":-1946388514,"x":-285,"y":107,"width":32,"height":32,"inputConnectorIDs":[162930],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"End Job Reporting Success"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"162932":{"id":162932,"inputCardinality":"ONE","outputCardinality":"ZERO","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":515156205,"x":-80,"y":-32,"width":32,"height":32,"inputConnectorIDs":[162935],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"End Job Reporting Failure"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]}},"successConnectors":{"162706":{"id":162706,"sourceID":162697,"targetID":162163},"162930":{"id":162930,"sourceID":162815,"targetID":162927},"162659":{"id":162659,"sourceID":162626,"targetID":162656},"161008":{"id":161008,"sourceID":160986,"targetID":160964},"162820":{"id":162820,"sourceID":162656,"targetID":162815},"162213":{"id":162213,"sourceID":162163,"targetID":160986},"162629":{"id":162629,"sourceID":162348,"targetID":162626},"162249":{"id":162249,"sourceID":160964,"targetID":162246},"162351":{"id":162351,"sourceID":162246,"targetID":162348}},"failureConnectors":{"162935":{"id":162935,"sourceID":162815,"targetID":162932}},"unconditionalConnectors":{"162703":{"id":162703,"sourceID":160960,"targetID":162697}},"trueConnectors":{},"falseConnectors":{},"iterationConnectors":{},"noteConnectors":{},"canUndo":true,"undoCommand":"Set Parameter","undoCreated":1564724234921,"canRedo":false,"redoCommand":"","redoCreated":-1,"notes":{"163354":{"id":163354,"x":-1478,"y":-204,"width":250,"height":58,"text":"Matillion ETL Pipeline to import Game and Player Profile data from AWS S3 and via Player Profile API and import into a Data Warehouse. \nThe ETL also creates the Staging tables, S3 Stage, FIle format, DIm and Fact tables if it doesn't exist.\nIt also has a step create views to provide data insights about the game and the players.\n\nThe process uses pre-configured Snowflake Database connection.\nIt can also use pre-defined AWS S3 connection.","colour":"e6e63c"}},"variables":{},"grids":{}}],"transformationJobs":[],"variables":[{"name":"AlertSeverity","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"CompressionType","type":"TEXT","scope":"TASKBATCH","description":"To hold compression type such gzip etc","visibility":"PUBLIC"},{"name":"DataMoverDataSetID","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"DataMoverETLID","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"DataMoverTaskID","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"DestDB","type":"TEXT","scope":"TASKBATCH","description":"Destination Database Environment","visibility":"PUBLIC"},{"name":"DestSchema","type":"TEXT","scope":"TASKBATCH","description":"Database Schema to hold destination data tables","visibility":"PUBLIC"},{"name":"DestTable","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"DestTableInsert","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"ElapsedDuration","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"EndDate","type":"DATETIME","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Environment","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"ETLExecutionID","type":"DECIMAL","scope":"TASKBATCH","description":"Execution ID from the DATAMOVER.DEV.ETL_EXECUTION table","visibility":"PUBLIC"},{"name":"FileType","type":"TEXT","scope":"TASKBATCH","description":"Variable to hold file type","visibility":"PUBLIC"},{"name":"IsFullPull","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"IterationsAttempted","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"IterationsGenerated","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"IterationsSuccessfull","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Load_StartDateTime","type":"DATETIME","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"MergeResultInsert","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"MergeResultUpdate","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Message","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"PackageName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Purge_S3_Files","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Query_ID","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"RowCount","type":"DECIMAL","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"RowCount_Updates","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"S3_EncryptionType","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"S3_FilePattern","type":"TEXT","scope":"TASKBATCH","description":"FileName Prefix for the data files in S3 bucket","visibility":"PUBLIC"},{"name":"S3_FilePattern_NDJSON","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"S3_To_SF_ConfigTable","type":"TEXT","scope":"TASKBATCH","description":"Configuration table to hold properties, configurations, and metadata used by the Matillion Orchestrations and Transformation components and its properties","visibility":"PUBLIC"},{"name":"S3Bucket","type":"TEXT","scope":"TASKBATCH","description":"AWS S3 Bucket Storage Source","visibility":"PUBLIC"},{"name":"S3FileName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_FileFormat","type":"TEXT","scope":"TASKBATCH","description":"Variable to hold file format that is defined in Snowflake DB","visibility":"PUBLIC"},{"name":"SF_FileFormat_NDJSON","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_SQLString","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_Staging_TableName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_Staging_TableName_NDJSON","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_Warehouse_CmdType","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_Warehouse_Size","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"SF_WarehouseName","type":"TEXT","scope":"TASKBATCH","description":"Warehouse name in Snowflake","visibility":"PUBLIC"},{"name":"StageName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"StageName_NDJSON","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"StagingSchema","type":"TEXT","scope":"TASKBATCH","description":"Database Schema to hold staging  data tables","visibility":"PUBLIC"},{"name":"StartDate","type":"DATETIME","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Status","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"TaskName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"TopicName","type":"TEXT","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},{"name":"Transform_JobName_NDJSON","type":"TEXT","scope":"BRANCH","description":"","visibility":"PUBLIC"}],"environments":[]}